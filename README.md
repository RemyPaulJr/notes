## **My Notes**

**Project:**
- Currently working on a DataPipeline
	- Extracting Data from API via Python requests library
	- Load Data into Google Cloud Storage (GCS)
	- Extract Data from GCS and cop/load into Snowflake raw table
	- Transform Data in silver table
	- Aggregate data in Gold table/layer
	- Load Data into GCS again
	- Load Data into BigQuery
	- Load Data into PowerBI or Looker maybe, will decide once I get closer to this step
	- Automate Pipeline via Airflow. Batch processing Jobs on set intervals
---
**More Data Engineering Related Learning:**
- Wanting to learn Databricks for Data Engineering. Maybe combine this with Azure as they have a seamless integration with Databricks notebook and can make use of the free credits.
- More Python. More SQL. Essential for Data Engineering.
- Learn Go. No timeline or priority for this. Just used to create most systems this day and age so want to stay competitive in my skillset.
- AI/LLM - So much hype around AI and ML, and for good reason. Also goes hand in hand with Data Engineering.
- PySpark. Super neccessary for DE, will be used with DataBricks as well.
- DataCamp grind. Have a yearly subscription I got half off so will be making use of it.
- dbt. Gold standard for transformations in DE.
- Docker. Really getting the hang of docker images and containers. Still more to learn and understand.
---
**CI/CD / DevOps / SysEnginer Learning:**
- Kubernetes. King of Orchestration. Want to implement on my home server. Maybe after finding my first role in DE?
- Start Proxmox or Kubernetes Homelab 
---
**For Job Hunting:**
- Keep resume up to date.
- Keep Github up to date.
- Keep website up to date with projects and some information from my Github as blog posts.
- Post and comment on L
- VIM
- Update Github and website to remy paul, for betting SEO having my government name present in search results.
- Starting AWS Data Engineer Certification study. Need to get this by Q4 to meet work requirement. Using Stephane Marek's udemy course with Frank